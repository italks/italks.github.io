# 【保姆级教程】正确使用 Ollama + OpenWebUI：3 个真实任务 + 可复制模板

- 你将直接获得：安装一键命令、3 个真实任务工作流、可复制 Prompt 模板、常见坑避坑清单
- 适合人群：产品/运营/技术个人创作者、中小团队，希望“低成本把 AI 真正用起来”
- 我的定位：既懂底层 Linux（Ubuntu）与应用层（APP 开发），也关心业务落地与增长

## 工具定位：一句话说清楚
- Ollama：在本地或服务器快速运行开源/闭源大模型的统一入口（如 Llama3、Qwen、Phi 等）
- OpenWebUI：给 Ollama 一个易用的网页端；支持多模型切换、文件知识库、工作流
- 组合优势：隐私可控、成本可控、响应稳定；适合把“个人探索”升级为“可复用生产线”

## 快速安装（Linux/Ubuntu 场景，含 Docker 方案）

### 0. 准备工作（显存建议）
- 8B 模型：至少 6GB 显存（RTX 3060/4060 级别）
- 32B 模型：至少 16GB-24GB 显存（RTX 3090/4090 级别）
- 纯 CPU 运行：由于 Ollama 优化极佳，8B 模型在 16GB 内存电脑上也能跑，但速度较慢。

### 1. 安装 Ollama（如已安装可跳过）

```bash
curl -fsSL https://ollama.com/install.sh | sh
# 验证
ollama --version
```

> **注意**：Linux 下安装脚本会自动注册 systemd 服务。如果你发现 `ollama serve` 报错端口占用，说明后台已经在运行了，直接用即可。

### 2. 拉取模型（推荐 DeepSeek-R1 与 Llama3）
```bash
# 强推理/逻辑分析（爆款推荐）：DeepSeek-R1 8B
ollama pull deepseek-r1:8b

# 通用英文/编程任务：Llama3 8B
ollama pull llama3:8b

# 中文通用对话：Qwen2.5 7B
ollama pull qwen2.5:7b
```

### 3. 安装并运行 OpenWebUI（Docker 推荐）

为了确保 OpenWebUI 能顺利连接宿主机上的 Ollama，我们需要添加 `--add-host` 参数。

```bash
# 如果你有 NVIDIA 显卡，建议加上 --gpus all
docker run -d \
  --name open-webui \
  -p 3000:3000 \
  --restart always \
  --add-host=host.docker.internal:host-gateway \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  ghcr.io/open-webui/open-webui:main
```

> **参数详解**：
> - `--add-host=host.docker.internal:host-gateway`：让容器内部能通过 `host.docker.internal` 访问宿主机（解决 Linux 下 Docker 无法直接访问 localhost 的问题）。
> - `-v open-webui:/app/backend/data`：强烈建议加上数据持久化（避免重启后聊天记录丢失），完整命令见文末资料包。

---

## 真实任务 1：把脑暴想法变成可执行 PRD

目标：从“一段想法”生成结构化 PRD 草案，便于团队协作与评审

步骤：
- 在 OpenWebUI 选择模型（推荐：DeepSeek-R1:8b 擅长深度思考；或 qwen2.5:7b）
- 粘贴“想法描述”，配合下方模板生成 PRD

可复制模板（PRD 结构化交付）：
```
你是一名资深产品经理。请将以下想法整理为可执行的 PRD 草案：

[我的想法]
（在此粘贴你的想法描述）

交付要求（Markdown）：
- 背景与目标（一句话）
- 关键用户与使用场景（3 个）
- 目标指标（可度量的 3 项）
- 功能列表（MVP 范围 + 非目标范围）
- 交互流程（关键路径步骤）
- 技术与数据需求（接口/字段/权限）
- 风险与边界（3 点）
- 里程碑（两周版本节奏）
```

---

## 真实任务 2：从长文中提取结构化数据（CSV/JSON）

目标：将“行业报告/访谈记录”抽取为表格，直接用于分析或建库

步骤：
- 在 OpenWebUI 上传长文或粘贴正文
- 使用 JSON Schema 提取结构

可复制模板（JSON Schema 提取）：
```
请阅读以下文本，按指定 JSON Schema 抽取结构化数据。

Schema：
{
  "公司": "string",
  "产品": "string",
  "发布日期": "string",
  "价格或版本": "string",
  "核心卖点": ["string"],
  "适用场景": ["string"]
}

输出必须是严格可解析的 JSON 数组，每个元素对应一条记录。
如果无信息，请返回空数组 []，不要编造。

[正文粘贴在此]
```

小技巧：
- 输出后复制到 CSV（OpenWebUI 支持导出），或用脚本直接入库
- 对“日期/价格”的不确定项，用 "unknown" 标注，避免幻觉

---

## 真实任务 3：写作提纲 → 完整文章（支持 Markdown）

目标：将主题快速拆成“提纲 → 段落 → 完整稿”，兼顾可读性与引用

步骤：
- 先用“提纲模板”拿到骨架
- 再用“段落扩写模板”生成正文

可复制模板（提纲生成）：
```
主题：{你的主题}
面向读者：入门-进阶混合读者
请生成一份可跳读的文章提纲（Markdown），包含：
- 开篇结论（3 句话）
- 3–5 个一级标题（每个 3–4 个要点）
- 必要的外部引用位（官方文档/论文/产品入口）
- 行动建议（读者读完下一步做什么）
```

可复制模板（段落扩写）：
```
基于以下提纲的某一节，扩写为 300–500 字的可读段落，并附 1 个可验证引用链接：
[粘贴你刚生成的提纲中的某一节]
```

---

## 常见坑与避坑
- 端口被占用：Linux 下 Ollama 默认自启动，如需手动调试，先执行 `sudo systemctl stop ollama`
- 显存/内存不足：Ollama 会自动把模型分层加载到内存，若跑不动，尝试 `q4_k_m` 量化版本或更小参数模型
- 中文效果：Qwen2.5 7B 目前在开源小模型中表现最佳；DeepSeek-R1 8B 适合做逻辑推理，但闲聊可能较慢
- 模型下载慢：使用国内镜像加速或在有梯子的机器下载后 export/import 迁移
- 权限与隐私：OpenWebUI 默认开放注册，建议在 Admin 面板关闭“允许新用户注册”，或开启白名单

---

## 适合谁用、谁不该用
- 适合：需要把“个人探索”变成“可复用流程”的团队/创作者
- 不适合：完全不愿做本地部署或对数据隐私毫不在意的人（直接用云端工具更省事）
- 替代方案：云端对话类工具 + 表格插件；但可控性与私密性较弱

---

## 资料包与更新（转粉设计）
- 关注本公众号，回复关键词【Ollama资料包】
- 我会发送：本篇全部 Prompt 合集（可复制）、工具清单、JSON 表格模板、部署脚本示例
- 更新节奏：每周 1 篇“教程/模板/清单”，每月 1 篇“热点全整理 + 我实测 + 结论”
- 错过不补发：资料包以当周版本为准，建议即刻领取

---

## 一句话结论
- 把“好用的工具”变成“可复用的生产线”，才是持续增长的关键
- 从今天开始，用上面的 3 个任务与模板，把 AI 真正落到成果物

